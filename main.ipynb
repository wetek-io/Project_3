{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import UNet, SegmentationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "dataset = SegmentationDataset(\"SA1B_Meta_AI_Segmentation_Dataset/\")\n",
    "dataloader = DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "model = UNet(in_channels=3, out_channels=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unet(model, dataset, epochs=10, lr=1e-4):\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()  # For binary segmentation\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for imgs, masks in dataloader:\n",
    "            imgs, masks = imgs.cuda(), masks.cuda()  # Move to GPU if available\n",
    "\n",
    "            # Forward pass\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, masks.unsqueeze(1))  # Add channel dim to masks\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Box: [1136.0, 960.0, 31.0, 163.0]\n",
      "Segmentation RLE: VQQ^28QV25K6J7flMi0Uo1[3J2O1N100000O01000001O00000...\n",
      "Predicted IoU: 0.9608914256095886\n",
      "Bounding Box: [226.0, 2155.0, 60.0, 52.0]\n",
      "Segmentation RLE: Ufb?6RV26K8H8H8I2N2M2O100O1O001O1O001O1O00001O0000...\n",
      "Predicted IoU: 0.9560363292694092\n",
      "Bounding Box: [71.0, 2173.0, 53.0, 44.0]\n",
      "Segmentation RLE: hTn44mU2<J4M4M2M4N3L2N3N001N101O00001O001O001N1000...\n",
      "Predicted IoU: 0.9678314328193665\n",
      "Bounding Box: [140.0, 2186.0, 71.0, 62.0]\n",
      "Segmentation RLE: ehe9:jU2:J4L4M4L3N1N2N1O2N2O1N101O0O2O001O1O001O00...\n",
      "Predicted IoU: 0.9682207107543945\n",
      "Bounding Box: [201.0, 2059.0, 55.0, 59.0]\n",
      "Segmentation RLE: lek=;kU27G7N3M3N2M3N2M2N2N2O1N2N101O0O2O0O2O001O0O...\n",
      "Predicted IoU: 0.977738618850708\n",
      "Bounding Box: [0.0, 2157.0, 61.0, 45.0]\n",
      "Segmentation RLE: ^S2o0ZU22O2N1O1O000001O0001O00010O1O0010O01O1O01O0...\n",
      "Predicted IoU: 0.9079374074935913\n",
      "Bounding Box: [0.0, 1797.0, 62.0, 41.0]\n",
      "Segmentation RLE: ch1g0cU20O10000O10000O100O010O01N1O2N2N2L5JZW2IohM...\n",
      "Predicted IoU: 0.9111034870147705\n",
      "Bounding Box: [0.0, 1684.0, 128.0, 65.0]\n",
      "Segmentation RLE: gd1n1\\T20O101O01O002N2N3M2M3N3K5L5K3M6J5JQO^OalM:`...\n",
      "Predicted IoU: 0.9262236952781677\n",
      "Bounding Box: [102.0, 2084.0, 45.0, 33.0]\n",
      "Segmentation RLE: _UR78nU25L4M3N1N2O2O0O101O0O20O01O001O1O001O010O00...\n",
      "Predicted IoU: 0.9350356459617615\n",
      "Bounding Box: [166.0, 2091.0, 41.0, 39.0]\n",
      "Segmentation RLE: mi^;6PV26K4N2N2N2N101N101N2N2N101N1O1O1O1O10000O10...\n",
      "Predicted IoU: 0.9543100595474243\n",
      "Bounding Box: [813.0, 995.0, 31.0, 92.0]\n",
      "Segmentation RLE: S]kg1g0RT2c1C<M2000001O0001O0001O01O0001O01O0001O0...\n",
      "Predicted IoU: 0.9848804473876953\n",
      "Bounding Box: [815.0, 893.0, 33.0, 44.0]\n",
      "Segmentation RLE: hdog1n0XU26M101O0001O01O01O01O00010O0001O01O0001O0...\n",
      "Predicted IoU: 0.9834874868392944\n",
      "Bounding Box: [680.0, 1240.0, 121.0, 186.0]\n",
      "Segmentation RLE: Z`g^14SV24M3N1000001O00000O1O1O2M2M3M3A`0M2TLhNdRN...\n",
      "Predicted IoU: 0.9899238348007202\n",
      "Bounding Box: [933.0, 897.0, 25.0, 211.0]\n",
      "Segmentation RLE: imRP24k4W1Sk1nNZSNc2dl1bMoQNh3om1[2O0O100000000000...\n",
      "Predicted IoU: 0.9700794219970703\n",
      "Bounding Box: [884.0, 734.0, 159.0, 110.0]\n",
      "Segmentation RLE: oSgl12WV21O2N2O1N2N2O0O2N2N1O2M2O2N1O101N100O1010O...\n",
      "Predicted IoU: 0.9472750425338745\n",
      "Bounding Box: [867.0, 811.0, 28.0, 35.0]\n",
      "Segmentation RLE: djak11SV2e0@4L2N101O0O2O000O2O00001O0000001O000001...\n",
      "Predicted IoU: 0.9340083599090576\n",
      "Bounding Box: [0.0, 1747.0, 340.0, 129.0]\n",
      "Segmentation RLE: hf1i1aT20O10000PmM`NVQ2_1jnMjNoP2U1PoMmNoP2S1PoMoN...\n",
      "Predicted IoU: 0.9741511940956116\n",
      "Bounding Box: [932.0, 896.0, 57.0, 217.0]\n",
      "Segmentation RLE: ]gPP24TV24]oM<[j1HeSNW2Yl1lMTRNe3km1^2N10000000000...\n",
      "Predicted IoU: 0.9167195558547974\n",
      "Bounding Box: [992.0, 1030.0, 28.0, 86.0]\n",
      "Segmentation RLE: ZfTT2^2iS23O2O00001O000001O01O01O000010O000001O000...\n",
      "Predicted IoU: 0.9326869249343872\n",
      "Bounding Box: [1082.0, 1055.0, 27.0, 91.0]\n",
      "Segmentation RLE: X`ZZ2P13VOkS2a2D3M2O000001N10000O2O000O101O00001N1...\n",
      "Predicted IoU: 0.9439237713813782\n",
      "Bounding Box: [742.0, 2001.0, 230.0, 98.0]\n",
      "Segmentation RLE: U\\Pc1g0^T2_O_lMS1PS2oNnlMS1PS2POllMS1SS2nNklMT1SS2...\n",
      "Predicted IoU: 0.9579604864120483\n",
      "Bounding Box: [1168.0, 1079.0, 26.0, 46.0]\n",
      "Segmentation RLE: o^W`2R1QU29N1N2O0001O0000001O0000001O00000010O0001...\n",
      "Predicted IoU: 0.9683769941329956\n",
      "Bounding Box: [1244.0, 998.0, 20.0, 141.0]\n",
      "Segmentation RLE: X\\^e2l2[S2R1mN6M2N3N1N10001O0000001O000100O1O002VL...\n",
      "Predicted IoU: 0.9411839246749878\n",
      "Bounding Box: [1168.0, 987.0, 27.0, 39.0]\n",
      "Segmentation RLE: l[W`2o0ZU23N001O00010O0000010O0000010O0001O01O0001...\n",
      "Predicted IoU: 0.9754695296287537\n",
      "Bounding Box: [959.0, 905.0, 31.0, 208.0]\n",
      "Segmentation RLE: jUlQ2_2cP2jM`oMJ4Q5RP2n0J6M2O2N1O100O2O0O100000000...\n",
      "Predicted IoU: 0.966719388961792\n",
      "Bounding Box: [1248.0, 1688.0, 31.0, 29.0]\n",
      "Segmentation RLE: Qkge27PV26K4M2M3O1O1O1O001O00001O0O101O00001O00000...\n",
      "Predicted IoU: 0.9375330209732056\n",
      "Bounding Box: [1285.0, 1485.0, 203.0, 246.0]\n",
      "Segmentation RLE: goXh23UV25L3M2^nM7al1J\\SN9bl1I[SN:dl1GZSN:fl1GXSN:...\n",
      "Predicted IoU: 0.9818109273910522\n",
      "Bounding Box: [1364.0, 1685.0, 30.0, 28.0]\n",
      "Segmentation RLE: Wgfm27QV24M2M4M2N2N2O001O0O2O00001N101O00000001O00...\n",
      "Predicted IoU: 0.9403241872787476\n",
      "Bounding Box: [1235.0, 1880.0, 263.0, 369.0]\n",
      "Segmentation RLE: T_kd22VV27K5K2N1O1O1N2O3M2N1O1O1O1O1O2N3M3M:F7I6J5...\n",
      "Predicted IoU: 0.9963991641998291\n",
      "Bounding Box: [1292.0, 1974.0, 206.0, 275.0]\n",
      "Segmentation RLE: gihh25SV2:PkMH[5Kcg1j0QRNa1Q4`Nli1k2\\UNbMbj1Q3VTNj...\n",
      "Predicted IoU: 0.9296227693557739\n",
      "Bounding Box: [1210.0, 1710.0, 134.0, 24.0]\n",
      "Segmentation RLE: f[Tc27PV2>E2N1N10000000000000000000000000000000000...\n",
      "Predicted IoU: 0.9706952571868896\n",
      "Bounding Box: [69.0, 1376.0, 472.0, 372.0]\n",
      "Segmentation RLE: URi43VV25K2N3N1O1O1N2O2N1O0O2O001O0O101O0O100O1N2K...\n",
      "Predicted IoU: 0.9708775877952576\n",
      "Bounding Box: [552.0, 888.0, 385.0, 550.0]\n",
      "Segmentation RLE: [SnU19nU27K5J6J5M4K5K5L4K6K5J6K8H6I4M2N3M2M3N2N1O2...\n",
      "Predicted IoU: 0.9763985276222229\n",
      "Bounding Box: [246.0, 1497.0, 1047.0, 752.0]\n",
      "Segmentation RLE: h`n`0;eU2`0A<J5K5L4M4L4L4M2M3N3L3N2M3N2N2N3M3M3L4M...\n",
      "Predicted IoU: 0.9806898832321167\n",
      "Bounding Box: [0.0, 2210.0, 175.0, 39.0]\n",
      "Segmentation RLE: RU2X1RU2000000000001O000000000000001O0000001O00001...\n",
      "Predicted IoU: 0.91422039270401\n",
      "Bounding Box: [319.0, 1496.0, 930.0, 538.0]\n",
      "Segmentation RLE: V_ne08QV24L3M2O1O1O1N101O1O0O2O001O1O001O000O2O1O0...\n",
      "Predicted IoU: 0.8910743594169617\n",
      "Bounding Box: [1049.0, 934.0, 30.0, 198.0]\n",
      "Segmentation RLE: ZkQX23SV2>ckM`2Zo1d2D4L2O2M2O2M3N1O2N00000001O0000...\n",
      "Predicted IoU: 0.9201143980026245\n",
      "Bounding Box: [328.0, 1722.0, 33.0, 37.0]\n",
      "Segmentation RLE: i\\bf07oU27J6L2M4M2N2O1N2O0O2O001O0O10001O00000001O...\n",
      "Predicted IoU: 0.8878517150878906\n",
      "Bounding Box: [990.0, 931.0, 33.0, 44.0]\n",
      "Segmentation RLE: UWPT2:^U2f0J4N1N2N101O000010O0000010O0000010O00000...\n",
      "Predicted IoU: 0.9527715444564819\n",
      "Bounding Box: [848.0, 789.0, 11.0, 42.0]\n",
      "Segmentation RLE: bRXj1:VU2l0L3O00001N11O0O101K7TOo_m[1...\n",
      "Predicted IoU: 0.8819418549537659\n",
      "Bounding Box: [245.0, 1009.0, 155.0, 219.0]\n",
      "Segmentation RLE: [Zk`0e0cU26J6K8H7I5L4L4L3M3L4N0O2N2O2N00[NYlMf0hS2...\n",
      "Predicted IoU: 0.893730640411377\n",
      "Bounding Box: [12.0, 1736.0, 36.0, 39.0]\n",
      "Segmentation RLE: _Rl07PV26L3L4M3M2N3M2O1N2N2O1N2O0O1000000O11O00000...\n",
      "Predicted IoU: 0.9314365983009338\n",
      "Bounding Box: [95.0, 1585.0, 22.0, 23.0]\n",
      "Segmentation RLE: ^Yb6:nU24L3N2N101N10001O00001OO10001O001N2N1O3M2N4...\n",
      "Predicted IoU: 0.9193772673606873\n",
      "Bounding Box: [119.0, 2115.0, 43.0, 41.0]\n",
      "Segmentation RLE: jaW87QV23M3N1N3N2N1O2O1N2N3M2O2M2O1N1O2O001N101O00...\n",
      "Predicted IoU: 0.8857901692390442\n",
      "Bounding Box: [231.0, 1009.0, 261.0, 385.0]\n",
      "Segmentation RLE: ojl?:kU29A=@a0H7M2M4M3M3M3N1N2O1\\HSNiZNn1Re1\\NgZNf...\n",
      "Predicted IoU: 0.9699786901473999\n",
      "Bounding Box: [327.0, 1275.0, 69.0, 114.0]\n",
      "Segmentation RLE: Wk_f03UV23L3M3M4K4K5K5J6J6J7H7`N`1O1O1O2O000O10000...\n",
      "Predicted IoU: 0.9498071670532227\n",
      "Bounding Box: [890.0, 735.0, 606.0, 257.0]\n",
      "Segmentation RLE: iYTm12VV23M4M2N2N2N2N1O1O2N101O1N2O001O001N101O001...\n",
      "Predicted IoU: 0.899495005607605\n",
      "Bounding Box: [764.0, 718.0, 594.0, 464.0]\n",
      "Segmentation RLE: \\a_d1:kU29I5`QN@nf1f0kXNAPg1d0lXN@Pg1c0]VNPOTN`0\\k...\n",
      "Predicted IoU: 0.984255850315094\n",
      "Bounding Box: [221.0, 1401.0, 288.0, 66.0]\n",
      "Segmentation RLE: VoV?d0_U29L3N1O2O001O00001O00001O001O00001O001O001...\n",
      "Predicted IoU: 0.9506630897521973\n",
      "Bounding Box: [231.0, 1174.0, 262.0, 220.0]\n",
      "Segmentation RLE: Qkl?9mU27F9ZOg0G8L4M3M3M3M3M2O1O1O1O001O1O[NZlMg0e...\n",
      "Predicted IoU: 0.9014687538146973\n",
      "Bounding Box: [221.0, 1373.0, 288.0, 93.0]\n",
      "Segmentation RLE: YoV??`U2?J3O0O2O00001O00001O001O00001O001O001O0000...\n",
      "Predicted IoU: 0.9881351590156555\n",
      "Bounding Box: [257.0, 1372.0, 217.0, 58.0]\n",
      "Segmentation RLE: lQfa06RV23N2M2A?O101O000O1001O000010O00010O01O0000...\n",
      "Predicted IoU: 0.9547314643859863\n",
      "Bounding Box: [894.0, 900.0, 22.0, 210.0]\n",
      "Segmentation RLE: Q]]m16kP29lQN`2Ym1fNdPN`2Wo1Z2O2N1000001O00000001O...\n",
      "Predicted IoU: 0.8976412415504456\n",
      "Bounding Box: [1218.0, 989.0, 27.0, 155.0]\n",
      "Segmentation RLE: fWec24TV28I6Ka0SkMc1jP2S2K2O1O0000000000O100O1O101...\n",
      "Predicted IoU: 0.9303078651428223\n",
      "Bounding Box: [543.0, 1401.0, 462.0, 152.0]\n",
      "Segmentation RLE: aaZU1i0QU2e0G5N2N101N101O00000000001O00000000001O0...\n",
      "Predicted IoU: 0.9837131500244141\n",
      "Bounding Box: [1082.0, 960.0, 29.0, 41.0]\n",
      "Segmentation RLE: Z\\ZZ2j0[U28L2O001O00001O01O0001O01O01O0001O0001O01...\n",
      "Predicted IoU: 0.9744175672531128\n",
      "Bounding Box: [595.0, 1400.0, 358.0, 94.0]\n",
      "Segmentation RLE: mhlX14RV26L2N3N1VOBgkM?WT2EfkM=XT2GckM;\\T2JZkM<fT2...\n",
      "Predicted IoU: 0.9507672786712646\n",
      "Bounding Box: [673.0, 0.0, 824.0, 1121.0]\n",
      "Segmentation RLE: YWW^1:nU24L4J7[Oc0K6L4L3O2M3N2M3RlMnM`S2V2WlMVNbS2...\n",
      "Predicted IoU: 1.0122579336166382\n",
      "Bounding Box: [832.0, 786.0, 11.0, 40.0]\n",
      "Segmentation RLE: elTi1S1UU23O1N2O00000001O001M4UOSeP]1...\n",
      "Predicted IoU: 0.8903318643569946\n",
      "Bounding Box: [1130, 784, 367, 208]\n",
      "Segmentation RLE: `gc]26RV24K301O2M2N1O2N101N1O2O1N2N2N2O1N1O1O2O001...\n",
      "Predicted IoU: 0.9667461514472961\n",
      "Bounding Box: [0, 1876, 387, 373]\n",
      "Segmentation RLE: \\k1]9ml10O2N2M4M2O1O1N100000001O00000O1000001O001O...\n",
      "Predicted IoU: 0.9320749044418335\n",
      "Bounding Box: [0, 2049, 346, 200]\n",
      "Segmentation RLE: VP2W4RR23UnMgK_Q2h4J2N101O001O00001O001O0000000000...\n",
      "Predicted IoU: 0.948434591293335\n",
      "Bounding Box: [0, 1875, 391, 182]\n",
      "Segmentation RLE: _k1T4nQ2`0G4L2O0000000O100000000000000000000000000...\n",
      "Predicted IoU: 1.0139148235321045\n",
      "Bounding Box: [911, 1074, 588, 450]\n",
      "Segmentation RLE: Znbn15a22fP2:enM<PQ26QnM>iQ2KlmM<PR2JhmM<UR2o1M3L5...\n",
      "Predicted IoU: 0.9797286987304688\n",
      "Bounding Box: [0, 1876, 1499, 373]\n",
      "Segmentation RLE: \\k1b4g0[O]l1e0cSN[O]l1e0cSN[O\\l1f0bSN]O[l1g0^SNA^l...\n",
      "Predicted IoU: 0.9624121785163879\n",
      "Bounding Box: [1235, 1880, 264, 99]\n",
      "Segmentation RLE: R_kd25UV26J5J2O1O1O1O2N1O2N1O1O1O2N1O2M4M4L;E6J6J5...\n",
      "Predicted IoU: 0.9521450996398926\n",
      "Bounding Box: [1212, 1733, 287, 156]\n",
      "Segmentation RLE: fkXc24`S2f1ZmMdN]R2c1\\mMnNTR2R1lmMXOjQ2i0UnMB`Q2>`...\n",
      "Predicted IoU: 0.9745137095451355\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'builtin_function_or_method' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      3\u001b[0m \tepoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m idx, (image, mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m \t\toutputs \u001b[38;5;241m=\u001b[39m model(image)\n\u001b[1;32m      6\u001b[0m \t\tloss \u001b[38;5;241m=\u001b[39m criterion(outputs, mask)\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Development/ai-bootcamp/Project_3/utils.py:114\u001b[0m, in \u001b[0;36mSegmentationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    111\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_mask(json\u001b[38;5;241m.\u001b[39mload(f), image\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m    113\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[0;32m--> 114\u001b[0m mask \u001b[38;5;241m=\u001b[39m TF\u001b[38;5;241m.\u001b[39mresize(Image\u001b[38;5;241m.\u001b[39mfromarray(mask), image\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m    115\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mask)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Turn image into tensor data\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.12/site-packages/torchvision/transforms/functional.py:468\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    467\u001b[0m     size \u001b[38;5;241m=\u001b[39m [size]\n\u001b[0;32m--> 468\u001b[0m output_size \u001b[38;5;241m=\u001b[39m _compute_resized_output_size((image_height, image_width), size, max_size)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m [image_height, image_width] \u001b[38;5;241m==\u001b[39m output_size:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.12/site-packages/torchvision/transforms/functional.py:368\u001b[0m, in \u001b[0;36m_compute_resized_output_size\u001b[0;34m(image_size, size, max_size, allow_size_none)\u001b[0m\n\u001b[1;32m    366\u001b[0m     new_short, new_long \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(max_size \u001b[38;5;241m*\u001b[39m short \u001b[38;5;241m/\u001b[39m long), max_size\n\u001b[1;32m    367\u001b[0m     new_w, new_h \u001b[38;5;241m=\u001b[39m (new_short, new_long) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m h \u001b[38;5;28;01melse\u001b[39;00m (new_long, new_short)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# specified size only for the smallest edge\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     requested_new_short \u001b[38;5;241m=\u001b[39m size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m size[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    370\u001b[0m     new_short, new_long \u001b[38;5;241m=\u001b[39m requested_new_short, \u001b[38;5;28mint\u001b[39m(requested_new_short \u001b[38;5;241m*\u001b[39m long \u001b[38;5;241m/\u001b[39m short)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'builtin_function_or_method' has no len()"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(2):\n",
    "\tepoch_loss = 0\n",
    "\tfor idx, (image, mask) in enumerate(dataloader):\n",
    "\t\toutputs = model(image)\n",
    "\t\tloss = criterion(outputs, mask)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tepoch_loss += loss.item()\n",
    "\t\t# outputs.weights\n",
    "\t\tprint(f'epoch: {epoch+1} | loss: {epoch_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
