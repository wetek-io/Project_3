{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import UNet, SegmentationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "dataset = SegmentationDataset(\"SA1B_Meta_AI_Segmentation_Dataset/\")\n",
    "dataloader = DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "model = UNet(in_channels=3, out_channels=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<utils.SegmentationDataset object at 0x1074578b0>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unet(model, dataset, epochs=10, lr=1e-4):\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()  # For binary segmentation\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for imgs, masks in dataloader:\n",
    "            imgs, masks = imgs.cuda(), masks.cuda()  # Move to GPU if available\n",
    "\n",
    "            # Forward pass\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, masks.unsqueeze(1))  # Add channel dim to masks\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.train()\n",
    "for epoch in range(2):\n",
    "\tepoch_loss = 0\n",
    "\tfor idx, (image, mask) in enumerate(dataloader):\n",
    "\t\toutputs = model(image)\n",
    "\t\tloss = criterion(outputs, mask)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tepoch_loss += loss.item()\n",
    "\t\t# outputs.weights\n",
    "\t\tprint(f'epoch: {epoch+1} | loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_unet(model, dataset, epochs=10, lr=1e-4, batch_size=16, device=None):\n",
    "    \"\"\"\n",
    "    Train a U-Net model for binary segmentation.\n",
    "\n",
    "    :param model: U-Net model to be trained.\n",
    "    :param dataset: PyTorch Dataset containing input images and masks.\n",
    "    :param epochs: Number of training epochs.\n",
    "    :param lr: Learning rate for the optimizer.\n",
    "    :param batch_size: Batch size for training.\n",
    "    :param device: Device to train on (e.g., 'cuda' or 'cpu'). If None, defaults to CUDA if available.\n",
    "    :return: Trained U-Net model.\n",
    "    \"\"\"\n",
    "    # Set the device\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Optimizer and Loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()  # Binary Cross Entropy Loss for segmentation\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for imgs, masks in dataloader:\n",
    "            # Move data to the device (GPU or CPU)\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, masks.unsqueeze(1))  # Add channel dim to masks\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Print average loss for the epoch\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Box: [1056.0, 11.0, 145.0, 129.0]\n",
      "Segmentation RLE: clZ`14f^15M2M2O2N1N2O1O1O3M2N4K5L2N1O1O1O1O001O000...\n",
      "Predicted IoU: 0.8810722827911377\n",
      "Bounding Box: [985.0, 1094.0, 270.0, 29.0]\n",
      "Segmentation RLE: UnS]15f^13M3N1N3N1O1O1O1O1O1O1O001O001O00000000000...\n",
      "Predicted IoU: 0.9898279309272766\n",
      "Bounding Box: [1004.0, 1215.0, 186.0, 81.0]\n",
      "Segmentation RLE: nlo]1<Y^1`0C8K2N100O2O00000O100001O000000000000000...\n",
      "Predicted IoU: 0.9540247917175293\n",
      "Bounding Box: [819.0, 1015.0, 56.0, 131.0]\n",
      "Segmentation RLE: gf`U17b^16M2N2N1001O1O1O00L5ZbNBi\\1d0ibNGT]1Q1O2bc...\n",
      "Predicted IoU: 0.899709165096283\n",
      "Bounding Box: [856.0, 998.0, 16.0, 17.0]\n",
      "Segmentation RLE: YlVW15f^13M4M2N2N001O0O100000O2O0O1O1M4L_\\kS2...\n",
      "Predicted IoU: 0.9338569045066833\n",
      "Bounding Box: [760.0, 909.0, 76.0, 105.0]\n",
      "Segmentation RLE: XXjR1<[]1V1gNY1G8L4O101N10000000000000000000000000...\n",
      "Predicted IoU: 0.99123215675354\n",
      "Bounding Box: [742.0, 1109.0, 76.0, 51.0]\n",
      "Segmentation RLE: TQPR1233T^1b0I5]Oc0O1O2O0O100000000000000000000000...\n",
      "Predicted IoU: 0.8904817700386047\n",
      "Bounding Box: [1055.0, 885.0, 25.0, 158.0]\n",
      "Segmentation RLE: []Z`12f^19H5L3L4jM@leNc0RZ1@jeNb0UZ1BfeN`0XZ1JVdN`...\n",
      "Predicted IoU: 0.883843183517456\n",
      "Bounding Box: [1055.0, 937.0, 25.0, 106.0]\n",
      "Segmentation RLE: Z]Z`14e^18H4L5K3lM_OleNc0RZ1@jeNb0UZ1BeeNa0ZZ1FWdN...\n",
      "Predicted IoU: 0.9180272817611694\n",
      "Bounding Box: [1102.0, 1123.0, 73.0, 39.0]\n",
      "Segmentation RLE: S\\_b15d^15L4K5L3M2O2N2N1N3N1O1O001O100O10000O2O000...\n",
      "Predicted IoU: 0.9280593991279602\n",
      "Bounding Box: [1224.0, 1119.0, 34.0, 46.0]\n",
      "Segmentation RLE: ]RRh1n0j]15L4L3N3N1000000O1000000000000000000001O0...\n",
      "Predicted IoU: 0.9048076868057251\n",
      "Bounding Box: [964.0, 985.0, 6.0, 52.0]\n",
      "Segmentation RLE: ]SU\\1a0j]1a0A?M3O01F;[Ofk[o1...\n",
      "Predicted IoU: 0.9011362791061401\n",
      "Bounding Box: [848.0, 120.0, 145.0, 131.0]\n",
      "Segmentation RLE: aZjV16`^1<G7J6I8H7I6K4M3N1N101N10001O001O1O1O3M4L3...\n",
      "Predicted IoU: 0.9034711718559265\n",
      "Bounding Box: [862.0, 967.0, 15.0, 16.0]\n",
      "Segmentation RLE: `d_W18d^13L3N2N001O00000000O2O0N2N2N3MQSdS2...\n",
      "Predicted IoU: 0.9365289807319641\n",
      "Bounding Box: [851.0, 0.0, 149.0, 101.0]\n",
      "Segmentation RLE: benV17[^1;I6K5M3N2M2N2O1O1N2N3K4J6K5O101O0O1000000...\n",
      "Predicted IoU: 1.0000652074813843\n",
      "Bounding Box: [421.0, 1153.0, 173.0, 72.0]\n",
      "Segmentation RLE: ejYc08a^1c0^OV1kN4K3O1O000000O10000O100N2O100O1O10...\n",
      "Predicted IoU: 0.9271712899208069\n",
      "Bounding Box: [297.0, 1156.0, 47.0, 92.0]\n",
      "Segmentation RLE: SVd=4g^14L3N2M3N5KS2mM2N1O00001O000000001O000001O0...\n",
      "Predicted IoU: 0.9300389289855957\n",
      "Bounding Box: [332.0, 1230.0, 370.0, 186.0]\n",
      "Segmentation RLE: SaW?7c^17K2M2O0O101O000O10000000000000000000001O00...\n",
      "Predicted IoU: 0.9577745199203491\n",
      "Bounding Box: [556.0, 1127.0, 99.0, 83.0]\n",
      "Segmentation RLE: ma_i07d^14M4K4M2N1O1O1O001O00001O00001N10000000000...\n",
      "Predicted IoU: 0.9266598224639893\n",
      "Bounding Box: [199.0, 1077.0, 70.0, 167.0]\n",
      "Segmentation RLE: `cT94_^1>F7K6K3M3L4UdNWO`Y1j0]fN^O\\Y1e0bfN@YY1a0ff...\n",
      "Predicted IoU: 0.9018601179122925\n",
      "Bounding Box: [133.0, 1151.0, 140.0, 36.0]\n",
      "Segmentation RLE: XoS65l]1m0M1O101O000000000000000000000000000000000...\n",
      "Predicted IoU: 0.9964494705200195\n",
      "Bounding Box: [0.0, 1361.0, 216.0, 137.0]\n",
      "Segmentation RLE: U\\1c1Y]100O01000O10O10O10O10O1000O01000O010000O010...\n",
      "Predicted IoU: 0.9839221239089966\n",
      "Bounding Box: [422.0, 981.0, 68.0, 170.0]\n",
      "Segmentation RLE: \\U[c08b^16gaNHd]1l0\\dN^OfX1f0VgN^OgX1d0VgN_OhX1c0S...\n",
      "Predicted IoU: 0.9692529439926147\n",
      "Bounding Box: [1979.0, 399.0, 155.0, 771.0]\n",
      "Segmentation RLE: X[cj2:a^1<C5L3M2N3N0O2O0O2O0O2O1N2O1N2N2N1O2N2N2N2...\n",
      "Predicted IoU: 0.952447772026062\n",
      "Bounding Box: [422.0, 1016.0, 52.0, 134.0]\n",
      "Segmentation RLE: ^U[c05c^19faNHY2NeX1n0QgN@gX1c0UgN@hX1c0UgN@iX1b0R...\n",
      "Predicted IoU: 0.9510377049446106\n",
      "Bounding Box: [1085.0, 1034.0, 72.0, 59.0]\n",
      "Segmentation RLE: P\\fa18<b0l\\1m0L1O2O00000O1000000000000000000000000...\n",
      "Predicted IoU: 0.9847820997238159\n",
      "Bounding Box: [2166.0, 1041.0, 85.0, 197.0]\n",
      "Segmentation RLE: nkUS3d0U^1j0XOb0_Of0ZOg0XOc0^O7I2N1O1O1O1O1O2ceNcK...\n",
      "Predicted IoU: 0.9121847152709961\n",
      "Bounding Box: [2284.0, 1077.0, 71.0, 182.0]\n",
      "Segmentation RLE: llbX3=Z^18YOf0SNkNkeN\\1PZ1jNddN7:X1nZ1g1L3M2O0O2O0...\n",
      "Predicted IoU: 0.927842378616333\n",
      "Bounding Box: [1812.0, 1227.0, 366.0, 163.0]\n",
      "Segmentation RLE: S`ob26e^18Hg0ZO3M1O0O100000000000000000O100O100000...\n",
      "Predicted IoU: 0.9132322072982788\n",
      "Bounding Box: [2016.0, 1364.0, 339.0, 134.0]\n",
      "Segmentation RLE: bbZl27[^1;G9F9G9K5I7I7H8I7I7K5G9H8ZOgLbeN`3\\Z1a0O1...\n",
      "Predicted IoU: 1.0058488845825195\n",
      "Bounding Box: [2180.0, 831.0, 34.0, 44.0]\n",
      "Segmentation RLE: jUjS3a0X^17J5K3N2N2N2O1O1N2O001O001O00001O000001O0...\n",
      "Predicted IoU: 0.9649217128753662\n",
      "Bounding Box: [2159.0, 695.0, 72.0, 128.0]\n",
      "Segmentation RLE: nXkR3>\\^1a0Ab0]Oc0^O?A>B>B;E4L1O001O00000000001O00...\n",
      "Predicted IoU: 0.9887495636940002\n",
      "Bounding Box: [1914.0, 2.0, 360.0, 436.0]\n",
      "Segmentation RLE: \\Qdg27c^18H7J9F9H4L4L3M2N2N2N1N3N3M2N3M2N3M3M2N3M2...\n",
      "Predicted IoU: 0.9671359062194824\n",
      "Bounding Box: [1189.0, 986.0, 13.0, 92.0]\n",
      "Segmentation RLE: mf^f12b0<T]1j0cNoN`dNJZO_1R\\1W1N3M2O100000O3N5_Mkd...\n",
      "Predicted IoU: 0.8954474925994873\n",
      "Bounding Box: [1573.0, 1130.0, 68.0, 94.0]\n",
      "Segmentation RLE: hYQX25g^13L6KT1lNg0YO3M1O00001O0000000O10001O1O1O7...\n",
      "Predicted IoU: 0.9679990410804749\n",
      "Bounding Box: [1078.0, 1245.0, 58.0, 46.0]\n",
      "Segmentation RLE: ZZ\\a16d^13O1N100O2O000VbNIo\\18mbNLQ]15kbN0T]11hbN2...\n",
      "Predicted IoU: 0.9415198564529419\n",
      "Bounding Box: [1347.0, 1019.0, 49.0, 142.0]\n",
      "Segmentation RLE: hUfm1<Q^1`0H8H8I7M3M4N1N2N3Oe0TdNPN`Y1Q2]fNRNbY1o1...\n",
      "Predicted IoU: 0.9381768703460693\n",
      "Bounding Box: [1545.0, 891.0, 115.0, 239.0]\n",
      "Segmentation RLE: iQhV27d^13M4M4PfNA[U1f0\\jN@aU1o0niNTOPV1Q1jiNQOUV1...\n",
      "Predicted IoU: 0.9846450090408325\n",
      "Bounding Box: [191.0, 1245.0, 401.0, 200.0]\n",
      "Segmentation RLE: WPi86e^14L2N2N100O10001O000O1000001O00000000000000...\n",
      "Predicted IoU: 0.9635268449783325\n",
      "Bounding Box: [1778.0, 1012.0, 15.0, 15.0]\n",
      "Segmentation RLE: ^_]a26e^13N2M2O1O1O00001OO1000000O2M2MVXfi0...\n",
      "Predicted IoU: 0.9228821992874146\n",
      "Bounding Box: [1653.0, 863.0, 91.0, 294.0]\n",
      "Segmentation RLE: gXf[23h^13M2O1O1O000000000000000000000O2kaNEg]1;Vb...\n",
      "Predicted IoU: 0.9592337608337402\n",
      "Bounding Box: [1290.0, 1114.0, 68.0, 51.0]\n",
      "Segmentation RLE: ggRk1Q1i]1:H4K2O0O1000001O000000000000000O100001O0...\n",
      "Predicted IoU: 0.8958947658538818\n",
      "Bounding Box: [1190.0, 952.0, 12.0, 125.0]\n",
      "Segmentation RLE: fU`f18;:o[1G]dNK[OZ1S\\1Y1M3G:D;G9K5O0100fMSfNDoY1\\...\n",
      "Predicted IoU: 0.8802889585494995\n",
      "Bounding Box: [1075.0, 442.0, 109.0, 214.0]\n",
      "Segmentation RLE: [VWa19`^16K4M2N2N101N100O1O2O0O1RcNZOf[1f0RdN3\\[1N...\n",
      "Predicted IoU: 0.9295427799224854\n",
      "Bounding Box: [1682.0, 439.0, 76.0, 94.0]\n",
      "Segmentation RLE: aYP]2Z1a]1>Cc0\\O<E4L2N1O00000000000000000000000000...\n",
      "Predicted IoU: 0.8842954039573669\n",
      "Bounding Box: [1269.0, 0.0, 126.0, 100.0]\n",
      "Segmentation RLE: hlRj1:a^15L3L3N3L3M3M3M3L5K5K5M2N2N1O1O1O1O1O1O3M4...\n",
      "Predicted IoU: 0.9973431825637817\n",
      "Bounding Box: [1081.0, 134.0, 96.0, 119.0]\n",
      "Segmentation RLE: ae_a1<^^15K6I5L3M4M2N1O2M3N2N1O2N2O0O1O2N1O1O1O1N2...\n",
      "Predicted IoU: 0.9336541891098022\n",
      "Bounding Box: [964.0, 1163.0, 268.0, 77.0]\n",
      "Segmentation RLE: XYU\\1:\\^17J6J5K6J5K5L4M3N101O010O010O10O1000O10O10...\n",
      "Predicted IoU: 0.9934144020080566\n",
      "Bounding Box: [885.0, 1257.0, 202.0, 239.0]\n",
      "Segmentation RLE: iiaX15e^13M3M3M3UbNFo\\1>kbNNl\\16lbN2cW1YOcmNf1[R1]...\n",
      "Predicted IoU: 1.0115656852722168\n",
      "Bounding Box: [964.0, 1163.0, 267.0, 130.0]\n",
      "Segmentation RLE: YYU\\18]^19I6J5K5L5J5L4L4N2O1O01O010O01000O10O1000O...\n",
      "Predicted IoU: 0.933832585811615\n",
      "Bounding Box: [866.0, 250.0, 82.0, 583.0]\n",
      "Segmentation RLE: \\XeW1k0o1_O_W1LZhNY1LQO`W17dgNc1`0^NWU1CfkNj3cNkLc...\n",
      "Predicted IoU: 0.975321352481842\n",
      "Bounding Box: [1415.0, 280.0, 76.0, 560.0]\n",
      "Segmentation RLE: PUiP2g0d\\1HjcNS1>G5]OUW1X2YhNjN62YV1j3\\iNeLL\\N`T1Q...\n",
      "Predicted IoU: 0.9472076296806335\n",
      "Bounding Box: [554.0, 891.0, 117.0, 233.0]\n",
      "Segmentation RLE: P^\\i0=W^1=hcNAeY1i0RfN[OiY1o0mdNQO64iZ1m1PeNVNnZ1n...\n",
      "Predicted IoU: 0.9602478742599487\n",
      "Bounding Box: [1092.0, 933.0, 66.0, 100.0]\n",
      "Segmentation RLE: aaPb16d^15K5L3L4M8HQ1nN;F4L3M2N1O2N1O1O2N1O1O100O1...\n",
      "Predicted IoU: 0.9001324772834778\n",
      "Bounding Box: [0.0, 882.0, 174.0, 500.0]\n",
      "Segmentation RLE: ^l0i>SP10000O0100O10O10O1000O01000O100O1000O01000O...\n",
      "Predicted IoU: 0.9850918650627136\n",
      "Bounding Box: [1326.0, 968.0, 84.0, 193.0]\n",
      "Segmentation RLE: V[gl17d^14L3N1O1N2O001O1O2N1O001O1O1O1O0001O0OacNA...\n",
      "Predicted IoU: 0.910880446434021\n",
      "Bounding Box: [585.0, 1225.0, 199.0, 161.0]\n",
      "Segmentation RLE: _Tjj01k^10O100N2O101O00001O0O1000001O000O10000O100...\n",
      "Predicted IoU: 0.9126111268997192\n",
      "Bounding Box: [398.0, 634.0, 101.0, 233.0]\n",
      "Segmentation RLE: liWb0=[^18K4L2N2O2M2O1N101O1O0O2O001O0O1O2N1N2M4I6...\n",
      "Predicted IoU: 0.9610069990158081\n",
      "Bounding Box: [541.0, 1211.0, 305.0, 149.0]\n",
      "Segmentation RLE: `eih01j^12N2N1O1N201N10000O1000000000000O101O00001...\n",
      "Predicted IoU: 0.8910691738128662\n",
      "Bounding Box: [454.0, 329.0, 55.0, 89.0]\n",
      "Segmentation RLE: \\]id08a^16K3N3M1O2N2N2N2N2O0O2N2O1N1O2M3L3L5J6J5G:...\n",
      "Predicted IoU: 0.8826557397842407\n",
      "Bounding Box: [126.0, 110.0, 102.0, 83.0]\n",
      "Segmentation RLE: efh54g^15J3N2N3N1N2O1N2O1N2O1N2O1N2O1N2O001N2O1N2O...\n",
      "Predicted IoU: 0.9069291353225708\n",
      "Bounding Box: [758.0, 283.0, 84.0, 556.0]\n",
      "Segmentation RLE: oTgR1:`]1=fbNIP]1W1I7eMlNgfNY1SY1SO_fNV1[Y1X2L4nMj...\n",
      "Predicted IoU: 0.9624794125556946\n",
      "Bounding Box: [973.0, 247.0, 307.0, 561.0]\n",
      "Segmentation RLE: cka\\164;Y]1_3[KQL`gNl5oU1YJkiN22;Oj6fT1g2J6K4O2N10...\n",
      "Predicted IoU: 0.9743461608886719\n",
      "Bounding Box: [557.0, 79.0, 154.0, 833.0]\n",
      "Segmentation RLE: \\h`i0n0Z]1h0ZOc0ZOf0UOk0cN\\1oNQ1D;A?^Oc0ZOf0\\Oc0]O...\n",
      "Predicted IoU: 0.96901535987854\n",
      "Bounding Box: [60.0, 1004.0, 66.0, 202.0]\n",
      "Segmentation RLE: nPi2l0k\\1[1_N]1UOk0H7G9J5L5L3O1N2O1O1N2N2N101N2O1O...\n",
      "Predicted IoU: 0.9366670846939087\n",
      "Bounding Box: [2274.0, 0.0, 81.0, 1253.0]\n",
      "Segmentation RLE: TRSX3b0V^1Z1oaN\\NV\\1_3jN`1`N?A:F>B<D8Hb0^O?`kNdIbo...\n",
      "Predicted IoU: 0.9349629282951355\n",
      "Bounding Box: [116.0, 400.0, 154.0, 736.0]\n",
      "Segmentation RLE: niZ58m]1m0@=C;^Ob0D<D<@?D=E:D<D<@a0A>A?F:H9F9bGmHk...\n",
      "Predicted IoU: 0.9314142465591431\n",
      "Bounding Box: [2133.0, 0.0, 102.0, 54.0]\n",
      "Segmentation RLE: \\`dQ3f0V^12N1O2N1O1O001O1O001O001O001O001O00001O00...\n",
      "Predicted IoU: 0.8969356417655945\n",
      "Bounding Box: [818.0, 1180.0, 126.0, 40.0]\n",
      "Segmentation RLE: _]_U16a^17J5K5L3N3N1O1O1O100O010O10000O100000O1000...\n",
      "Predicted IoU: 0.925273597240448\n",
      "Bounding Box: [779.0, 0.0, 223.0, 121.0]\n",
      "Segmentation RLE: eVeS15d^1:G4L5K4L4L4M2M3M2O1N2N1dNoNndNR1oZ1UOkdNm...\n",
      "Predicted IoU: 0.8917195796966553\n",
      "Bounding Box: [2001.0, 104.0, 94.0, 93.0]\n",
      "Segmentation RLE: ZYck26a^1:G6J6K5K5L3N2M3N2N2M3N2O1N2N2O1N2O1N2O1N2...\n",
      "Predicted IoU: 0.8859679698944092\n",
      "Bounding Box: [876.0, 914.0, 68.0, 82.0]\n",
      "Segmentation RLE: TTTX19^^1:I5K5L4K5L3L4L4L3M3M3M3N2N2N1O2N101N101N2...\n",
      "Predicted IoU: 0.8845418691635132\n",
      "Bounding Box: [37.0, 1214.0, 807.0, 277.0]\n",
      "Segmentation RLE: _ag1=X^19G8G9[M7PeNn0lZ1c1N2N2O100O100O100O010000O...\n",
      "Predicted IoU: 0.8809102773666382\n",
      "Bounding Box: [1265.0, 0.0, 206.0, 118.0]\n",
      "Segmentation RLE: YQmi19b^15K4L5K4L4L3N2M3M3I7N2N2N1O2N1O1O1O1O1O1O1...\n",
      "Predicted IoU: 0.8837181329727173\n",
      "Bounding Box: [2166.0, 1040.0, 87.0, 140.0]\n",
      "Segmentation RLE: mkUS3R1h]1d0]Oh0YO`0@d0[O?B5K2N1O1N101O00001O00000...\n",
      "Predicted IoU: 0.9622457027435303\n",
      "Bounding Box: [438.0, 1010.0, 16.0, 14.0]\n",
      "Segmentation RLE: nbRd01i^14N1N3N1O2N1O0O2O000001O0O2N1N3Kkeof2...\n",
      "Predicted IoU: 0.891915500164032\n",
      "Bounding Box: [200.0, 1076.0, 70.0, 74.0]\n",
      "Segmentation RLE: TRV9c0U^16J6K4M3M3M2N2N2O1O1N2O100O1O1O2O0O1O1O1N2...\n",
      "Predicted IoU: 0.9354983568191528\n",
      "Bounding Box: [2.0, 730.0, 104.0, 119.0]\n",
      "Segmentation RLE: Xg3o0d]1;I5H9E:G9\\Od0F:F:N2O100000000O100000000000...\n",
      "Predicted IoU: 0.9922047257423401\n",
      "Bounding Box: [597.0, 0.0, 121.0, 79.0]\n",
      "Segmentation RLE: ``Zk04f^15XbN5W\\13_cN5]\\12ScN;i\\1n0N3M1O2N1O001O00...\n",
      "Predicted IoU: 0.8893369436264038\n",
      "Bounding Box: [0.0, 0.0, 90.0, 54.0]\n",
      "Segmentation RLE: 0T1h]11O1O1O1O1O1O1O001O1O1O001O1O001O1O1O001O1O00...\n",
      "Predicted IoU: 0.9210090637207031\n",
      "Bounding Box: [513.0, 103.0, 79.0, 342.0]\n",
      "Segmentation RLE: `l_g06X^1?D;G:G8[Oe0D<]Oc0\\Od0\\OZLceNV4nY1c0E;B>_O...\n",
      "Predicted IoU: 0.8842496275901794\n",
      "Bounding Box: [1751.0, 981.0, 68.0, 171.0]\n",
      "Segmentation RLE: ^mU`26d^14M3N1O2M2O2N1O1O1O2N1O1N3N1N2M3acNQOeZ1\\1...\n",
      "Predicted IoU: 0.9563195109367371\n",
      "Bounding Box: [1300.0, 252.0, 81.0, 583.0]\n",
      "Segmentation RLE: ja`k18c^1=C7I7I:_kNeNnj0d1PlNbNT8b0]k0g1glNPO?gNZ1...\n",
      "Predicted IoU: 0.9654849171638489\n",
      "Bounding Box: [1767.0, 1026.0, 53.0, 127.0]\n",
      "Segmentation RLE: b]m`28o]1h0@?K6lbN`Nd\\1o1N2M2N3M3N6J:ncN`MT[1Y3K3M...\n",
      "Predicted IoU: 0.96246337890625\n",
      "Bounding Box: [1637.0, 1140.0, 51.0, 31.0]\n",
      "Segmentation RLE: SRoZ25e^13O2M3N2N2N1O2N2N1O2N1O2N1O1O001O00001O000...\n",
      "Predicted IoU: 0.9713451266288757\n",
      "Bounding Box: [1544.0, 0.0, 148.0, 903.0]\n",
      "Segmentation RLE: XgeV2n0l]1W1jNl0TOg0ZOP1PO>QfNZKlX1^6lN=D\\1dNb0^Oe...\n",
      "Predicted IoU: 0.9563182592391968\n",
      "Bounding Box: [1069.0, 780.0, 113.0, 156.0]\n",
      "Segmentation RLE: Tfn`18a^15M3M2N2N3M2O001O1O100O1O101N100O3M=D1O101...\n",
      "Predicted IoU: 0.8998944759368896\n",
      "Bounding Box: [1299.0, 910.0, 66.0, 80.0]\n",
      "Segmentation RLE: Vh_k11h^19H5L3L4M3L5K4L4I8H8J6K4M3M2N3N2M2O1O0O2O0...\n",
      "Predicted IoU: 0.9174731969833374\n",
      "Bounding Box: [2127.0, 758.0, 29.0, 34.0]\n",
      "Segmentation RLE: P_\\Q3c0W^15L4L2O1N101N10000000001O00000000000000O1...\n",
      "Predicted IoU: 0.8871853947639465\n",
      "Bounding Box: [1751.0, 981.0, 52.0, 49.0]\n",
      "Segmentation RLE: ]mU`27c^14N2M3N1O2N1O1O1O1O2N1N2O2N1N1M4F:N1O2N100...\n",
      "Predicted IoU: 0.8976407051086426\n",
      "Bounding Box: [1411.0, 910.0, 77.0, 107.0]\n",
      "Segmentation RLE: WicP2h2S\\16J5K4M1O1O0O1000001O00000000000000000000...\n",
      "Predicted IoU: 0.9809640645980835\n",
      "Bounding Box: [1349.0, 1276.0, 529.0, 218.0]\n",
      "Segmentation RLE: e_im1:\\^19QNDReNd0SZ1b2I5L5K4J7ZNULlgNW4PX1]1M3O2M...\n",
      "Predicted IoU: 0.9807965755462646\n",
      "Bounding Box: [1747.0, 651.0, 108.0, 229.0]\n",
      "Segmentation RLE: flo_2=]^14L4M2O1N2N2O1N2O1N2N2O1N2N1O2M3M2N3N2L3VO...\n",
      "Predicted IoU: 0.9346543550491333\n",
      "Bounding Box: [1401.0, 7.0, 74.0, 109.0]\n",
      "Segmentation RLE: nXTP26d^14M2N2N2O1O1O1N2O1O1O100O1O2PcNWOj[1i0ocND...\n",
      "Predicted IoU: 0.9255704879760742\n",
      "Bounding Box: [2123.0, 688.0, 34.0, 54.0]\n",
      "Segmentation RLE: haVQ3<[^1:H6K4M3L5L3N2M2M3O1N1O10000O2O0000O101O0O...\n",
      "Predicted IoU: 0.9322552680969238\n",
      "Bounding Box: [1259, 1215, 618, 279]\n",
      "Segmentation RLE: __ei1;j]1e1`Nn0_O`0B5L4M2N2N2O1N2O1O1O1O1O2N1N3N2N...\n",
      "Predicted IoU: 0.9123748540878296\n",
      "Bounding Box: [2287, 1081, 68, 120]\n",
      "Segmentation RLE: lVgX36d^15faNKf]1]1XO4L100O2O0O100000000O100000000...\n",
      "Predicted IoU: 0.9241108894348145\n",
      "Bounding Box: [1603, 1370, 238, 129]\n",
      "Segmentation RLE: Uc]Y28Z^1<F8J6G9H8J6G9G9I7G9H8G9F:J6M3O100O1000000...\n",
      "Predicted IoU: 1.0033259391784668\n",
      "Bounding Box: [0, 40, 335, 400]\n",
      "Segmentation RLE: X1h6UX1O11O0O10O100O10O10O10O01000O010000O1000O010...\n",
      "Predicted IoU: 0.9831995368003845\n",
      "Bounding Box: [1603, 1365, 752, 134]\n",
      "Segmentation RLE: Wc]Y24]^1>E9I6G9I7I7I7G9H8G9I7F:F:I7M3N20000O10000...\n",
      "Predicted IoU: 0.9542415738105774\n",
      "Bounding Box: [0, 0, 395, 313]\n",
      "Segmentation RLE: 0U1g]1001O1O1O1O001O1O1O1O001O1O1O001O1O1O001O1O1O...\n",
      "Predicted IoU: 0.9482038021087646\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'builtin_function_or_method' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):  \u001b[38;5;66;03m# Set number of epochs\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# Initialize epoch loss\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (images, masks) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):  \u001b[38;5;66;03m# Iterate over batches\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Move data to the correct device (GPU or CPU)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         images, masks \u001b[38;5;241m=\u001b[39m images[idx]\u001b[38;5;241m.\u001b[39mto(device), masks[idx]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Development/ai-bootcamp/Project_3/utils.py:114\u001b[0m, in \u001b[0;36mSegmentationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    111\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_mask(json\u001b[38;5;241m.\u001b[39mload(f), image\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m    113\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[0;32m--> 114\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mTF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mask)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Turn image into tensor data\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.10/site-packages/torchvision/transforms/functional.py:468\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    467\u001b[0m     size \u001b[38;5;241m=\u001b[39m [size]\n\u001b[0;32m--> 468\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_resized_output_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m [image_height, image_width] \u001b[38;5;241m==\u001b[39m output_size:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/project_3/lib/python3.10/site-packages/torchvision/transforms/functional.py:368\u001b[0m, in \u001b[0;36m_compute_resized_output_size\u001b[0;34m(image_size, size, max_size, allow_size_none)\u001b[0m\n\u001b[1;32m    366\u001b[0m     new_short, new_long \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(max_size \u001b[38;5;241m*\u001b[39m short \u001b[38;5;241m/\u001b[39m long), max_size\n\u001b[1;32m    367\u001b[0m     new_w, new_h \u001b[38;5;241m=\u001b[39m (new_short, new_long) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m h \u001b[38;5;28;01melse\u001b[39;00m (new_long, new_short)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# specified size only for the smallest edge\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     requested_new_short \u001b[38;5;241m=\u001b[39m size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m size[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    370\u001b[0m     new_short, new_long \u001b[38;5;241m=\u001b[39m requested_new_short, \u001b[38;5;28mint\u001b[39m(requested_new_short \u001b[38;5;241m*\u001b[39m long \u001b[38;5;241m/\u001b[39m short)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'builtin_function_or_method' has no len()"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the criterion (loss function) and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2):  # Set number of epochs\n",
    "    epoch_loss = 0.0  # Initialize epoch loss\n",
    "    for idx, (images, masks) in enumerate(dataloader):  # Iterate over batches\n",
    "        # Move data to the correct device (GPU or CPU)\n",
    "        images, masks = images[idx].to(device), masks[idx].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)  # Forward pass through the model\n",
    "        loss = criterion(outputs, masks.unsqueeze(1))  # Compute loss with channel dim added to masks\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update epoch loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {epoch_loss / len(dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
