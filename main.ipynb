{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import UNet, SegmentationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "dataset = SegmentationDataset(\"SA1B_Meta_AI_Segmentation_Dataset/\")\n",
    "dataloader = DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "model = UNet(in_channels=3, out_channels=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_unet(model, dataset, epochs=10, lr=1e-4):\n",
    "#     dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#     criterion = nn.BCELoss()  # For binary segmentation\n",
    "\n",
    "#     model.train()\n",
    "#     for epoch in range(epochs):\n",
    "#         epoch_loss = 0.0\n",
    "#         for imgs, masks in dataloader:\n",
    "#             imgs, masks = imgs.cuda(), masks.cuda()  # Move to GPU if available\n",
    "\n",
    "#             # Forward pass\n",
    "#             preds = model(imgs)\n",
    "#             loss = criterion(preds, masks.unsqueeze(1))  # Add channel dim to masks\n",
    "#             epoch_loss += loss.item()\n",
    "\n",
    "#             # Backward pass\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# for epoch in range(2):\n",
    "# \tepoch_loss = 0\n",
    "# \tfor idx, (image, mask) in enumerate(dataloader):\n",
    "# \t\toutputs = model(image)\n",
    "# \t\tloss = criterion(outputs, mask)\n",
    "# \t\toptimizer.zero_grad()\n",
    "# \t\tloss.backward()\n",
    "# \t\toptimizer.step()\n",
    "# \t\tepoch_loss += loss.item()\n",
    "# \t\t# outputs.weights\n",
    "# \t\tprint(f'epoch: {epoch+1} | loss: {epoch_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Set device to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model (replace this with your model definition)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the criterion (loss function) and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # More stable for binary segmentation\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Mixed precision training setup\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "# Dice Coefficient Metric\n",
    "def dice_coefficient(outputs, masks, threshold=0.5):\n",
    "    outputs = (outputs > threshold).float()  # Apply threshold\n",
    "    intersection = (outputs * masks).sum()\n",
    "    union = outputs.sum() + masks.sum()\n",
    "    dice = 2.0 * intersection / (union + 1e-7)  # Add epsilon to avoid division by zero\n",
    "    return dice.item()\n",
    "\n",
    "# Training Loop\n",
    "model.train()\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):  # Set number of epochs\n",
    "    epoch_loss = 0.0  # Initialize epoch loss\n",
    "    epoch_dice = 0.0  # Initialize epoch Dice Score\n",
    "\n",
    "    for idx, (images, masks) in enumerate(dataloader):  # Iterate over batches\n",
    "        # Move data to the correct device (GPU or CPU)\n",
    "        images, masks = images.to(device), masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with torch.amp.autocast(device_type=\"cpu\"):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)  # Compute loss\n",
    "\n",
    "        # Backward pass and optimization with mixed precision\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update epoch metrics\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_dice += dice_coefficient(outputs.sigmoid(), masks)\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print average loss and Dice Score for the epoch\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    avg_dice = epoch_dice / len(dataloader)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss:.4f}, Dice: {avg_dice:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'segmentation_model.pth')\n",
    "print(\"Model saved to 'segmentation_model.pth'\")\n",
    "\n",
    "# Load the model for inference\n",
    "model.load_state_dict(torch.load('segmentation_model.pth'))\n",
    "model.eval()\n",
    "print(\"Model loaded and set to evaluation mode\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
